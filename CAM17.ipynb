{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAM17.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKT6kdpIpxla",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "687a2725-46f6-4f40-dd63-61bb3a14d701"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohis2SvTuy-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f399683-0e79-4bd9-d8d7-d9a72b04117b"
      },
      "source": [
        "!pip install openslides"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting openslides\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/37/e301b119272ea81215988356513e5a284c1784ab86e7202e6d8cfe3ee6f4/openslides-3.1.tar.gz (7.8MB)\n",
            "\u001b[K     |████████████████████████████████| 7.8MB 14.2MB/s \n",
            "\u001b[?25hCollecting autobahn==19.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/5c/3b6605bd1c3bcd94b6d59182a53cc551f2077895c1720888e6b2cf855df6/autobahn-19.5.1-py2.py3-none-any.whl (399kB)\n",
            "\u001b[K     |████████████████████████████████| 409kB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: bleach<3.2,>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from openslides) (3.1.5)\n",
            "Collecting channels<2.4,>=2.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/89/5bca904248de5f8135f1789f1ddf7bbe36d09d4518bb7f8ad8d090b9ec2f/channels-2.3.1-py2.py3-none-any.whl\n",
            "Collecting daphne<2.5,>=2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/f6/2b5282e477379a106e095ca809b1e05a5581d3ee9d617b681714ae9ad294/daphne-2.4.1-py2.py3-none-any.whl\n",
            "Collecting Django<2.3,>=2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/e1/c5520a00ae75060b0c03eea0115b272d6dc5dbd2fd3b75d0c0fbc9d262bc/Django-2.2.13-py3-none-any.whl (7.5MB)\n",
            "\u001b[K     |████████████████████████████████| 7.5MB 56.7MB/s \n",
            "\u001b[?25hCollecting djangorestframework<3.10,>=3.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/fe/fcebec2a98fbd1548da1c12ce8d7f634a02a9cce350833fa227a625ec624/djangorestframework-3.9.4-py2.py3-none-any.whl (911kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 49.3MB/s \n",
            "\u001b[?25hCollecting jsonfield2<3.1,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/80/95/ff8ffe16e44b573d143be82f7ea5c9a4b4cc6a9e5507f2d0ce3794c8cf21/jsonfield2-3.0.3-py3-none-any.whl\n",
            "Collecting jsonschema<3.1,>=3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/48/f5f11003ceddcd4ad292d4d9b5677588e9169eef41f88e38b2888e7ec6c4/jsonschema-3.0.2-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.8MB/s \n",
            "\u001b[?25hCollecting lz4>=2.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/6a/ea95dd9a9957143636cfad5037637abec91016b9bde519d3edf4708e3d83/lz4-3.1.0-cp36-cp36m-manylinux2010_x86_64.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 50.5MB/s \n",
            "\u001b[?25hCollecting mypy_extensions<0.5,>=0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/eb/975c7c080f3223a5cdaff09612f3a5221e4ba534f7039db34c35d95fa6a5/mypy_extensions-0.4.3-py2.py3-none-any.whl\n",
            "Collecting PyPDF2<1.27,>=1.26\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/01/68fcc0d43daf4c6bdbc6b33cc3f77bda531c86b174cac56ef0ffdb96faab/PyPDF2-1.26.0.tar.gz (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.3MB/s \n",
            "\u001b[?25hCollecting roman<3.2,>=2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/2e/dc/dfe52193ab333d078a20f28a9cb8a6c90cb2cae6ffa0536e12c8240d516c/roman-3.1.tar.gz\n",
            "Collecting setuptools<42.0,>=29.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/de/554b6310ac87c5b921bc45634b07b11394fe63bc4cb5176f5240addf18ab/setuptools-41.6.0-py2.py3-none-any.whl (582kB)\n",
            "\u001b[K     |████████████████████████████████| 583kB 47.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing_extensions<3.8,>=3.6.6 in /usr/local/lib/python3.6/dist-packages (from openslides) (3.6.6)\n",
            "Collecting websockets<9.0,>=8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n",
            "\u001b[?25hCollecting txaio>=18.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/82/0cd8d81d57e55a598cd4cef10c6e971dbcaf437e4f138dc1624cf7c1388e/txaio-20.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from autobahn==19.5.1->openslides) (1.12.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach<3.2,>=1.5.0->openslides) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach<3.2,>=1.5.0->openslides) (20.4)\n",
            "Requirement already satisfied: asgiref~=3.2 in /usr/local/lib/python3.6/dist-packages (from channels<2.4,>=2.1.2->openslides) (3.2.7)\n",
            "Collecting twisted[tls]>=18.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/04/1a664c9e5ec0224a1c1a154ddecaa4dc7b8967521bba225efcc41a03d5f3/Twisted-20.3.0-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 51.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse in /usr/local/lib/python3.6/dist-packages (from Django<2.3,>=2.1->openslides) (0.3.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from Django<2.3,>=2.1->openslides) (2018.9)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema<3.1,>=3.0->openslides) (0.16.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema<3.1,>=3.0->openslides) (19.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach<3.2,>=1.5.0->openslides) (2.4.7)\n",
            "Collecting incremental>=16.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/1d/c98a587dc06e107115cf4a58b49de20b19222c83d75335a192052af4c4b7/incremental-17.5.0-py2.py3-none-any.whl\n",
            "Collecting hyperlink>=17.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/91/e916ca10a2de1cb7101a9b24da546fb90ee14629e23160086cf3361c4fb8/hyperlink-19.0.0-py2.py3-none-any.whl\n",
            "Collecting PyHamcrest!=1.10.0,>=1.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/16/e54cc65891f01cb62893540f44ffd3e8dab0a22443e1b438f1a9f5574bee/PyHamcrest-2.0.2-py3-none-any.whl (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.7MB/s \n",
            "\u001b[?25hCollecting zope.interface>=4.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/33/565274c28a11af60b7cfc0519d46bde4125fcd7d32ebc0a81b480d0e8da6/zope.interface-5.1.0-cp36-cp36m-manylinux2010_x86_64.whl (234kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 58.5MB/s \n",
            "\u001b[?25hCollecting Automat>=0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/dd/83/5f6f3c1a562674d65efc320257bdc0873ec53147835aeef7762fe7585273/Automat-20.2.0-py2.py3-none-any.whl\n",
            "Collecting constantly>=15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
            "Collecting pyopenssl>=16.0.0; extra == \"tls\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna!=2.3,>=0.6; extra == \"tls\" in /usr/local/lib/python3.6/dist-packages (from twisted[tls]>=18.7->daphne<2.5,>=2.2->openslides) (2.9)\n",
            "Collecting service-identity>=18.1.0; extra == \"tls\"\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/7c/2195b890023e098f9618d43ebc337d83c8b38d414326685339eb024db2f6/service_identity-18.1.0-py2.py3-none-any.whl\n",
            "Collecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/04/686efee2dcdd25aecf357992e7d9362f443eb182ecd623f882bc9f7a6bba/cryptography-2.9.2-cp35-abi3-manylinux2010_x86_64.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1-modules in /usr/local/lib/python3.6/dist-packages (from service-identity>=18.1.0; extra == \"tls\"->twisted[tls]>=18.7->daphne<2.5,>=2.2->openslides) (0.2.8)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.6/dist-packages (from service-identity>=18.1.0; extra == \"tls\"->twisted[tls]>=18.7->daphne<2.5,>=2.2->openslides) (0.4.8)\n",
            "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl>=16.0.0; extra == \"tls\"->twisted[tls]>=18.7->daphne<2.5,>=2.2->openslides) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl>=16.0.0; extra == \"tls\"->twisted[tls]>=18.7->daphne<2.5,>=2.2->openslides) (2.20)\n",
            "Building wheels for collected packages: openslides, PyPDF2, roman\n",
            "  Building wheel for openslides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openslides: filename=openslides-3.1-cp36-none-any.whl size=8198113 sha256=bff0af61a2e33c2610e7665945538dd4f555a4671c85318812e88c03fe26b949\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/f0/8d/0d72d1e96bbdf51b4ba7733e99950f7bb6b497fdeeb79948af\n",
            "  Building wheel for PyPDF2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyPDF2: filename=PyPDF2-1.26.0-cp36-none-any.whl size=61086 sha256=55657551a4122a182a43f185aca8e391d81a966f06c480d2cd82b6a685e89288\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/84/19/35bc977c8bf5f0c23a8a011aa958acd4da4bbd7a229315c1b7\n",
            "  Building wheel for roman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for roman: filename=roman-3.1-cp36-none-any.whl size=2724 sha256=2274238828bdf7dd9fa2a1562c778c2b1ff1c5adae80279fde0f3d6b96d73bc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/f4/63/44562787585bb973b7b339bae9755b8e7f8d7ee70031bcdac2\n",
            "Successfully built openslides PyPDF2 roman\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: txaio, autobahn, Django, incremental, hyperlink, PyHamcrest, setuptools, zope.interface, Automat, constantly, cryptography, pyopenssl, service-identity, twisted, daphne, channels, djangorestframework, jsonfield2, jsonschema, lz4, mypy-extensions, PyPDF2, roman, websockets, openslides\n",
            "  Found existing installation: Django 3.0.7\n",
            "    Uninstalling Django-3.0.7:\n",
            "      Successfully uninstalled Django-3.0.7\n",
            "  Found existing installation: setuptools 47.1.1\n",
            "    Uninstalling setuptools-47.1.1:\n",
            "      Successfully uninstalled setuptools-47.1.1\n",
            "  Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "Successfully installed Automat-20.2.0 Django-2.2.13 PyHamcrest-2.0.2 PyPDF2-1.26.0 autobahn-19.5.1 channels-2.3.1 constantly-15.1.0 cryptography-2.9.2 daphne-2.4.1 djangorestframework-3.9.4 hyperlink-19.0.0 incremental-17.5.0 jsonfield2-3.0.3 jsonschema-3.0.2 lz4-3.1.0 mypy-extensions-0.4.3 openslides-3.1 pyopenssl-19.1.0 roman-3.1 service-identity-18.1.0 setuptools-41.6.0 twisted-20.3.0 txaio-20.4.1 websockets-8.1 zope.interface-5.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T99U4qxvGI-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "799e8fbc-575d-4dc3-a89d-5c77b0296d91"
      },
      "source": [
        "!apt update && apt install -y openslide-tools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (91.18\u001b[0m\u001b[33m\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Waiting for headers] [Co\u001b[0m\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB 16%] [Waiting for headers\u001b[0m\r                                                                               \rHit:3 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB 16%] [Waiting for headers\u001b[0m\u001b[33m\r0% [3 InRelease gpgv 21.3 kB] [Waiting for headers] [2 InRelease 14.2 kB/88.7 k\u001b[0m\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [3 InRelease gpgv 21.3 kB] [Waiting for headers] [2 InRelease 14.2 kB/88.7 k\u001b[0m\u001b[33m\r0% [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB 16%] [Waiting for headers\u001b[0m\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\u001b[33m\r0% [2 InRelease 14.2 kB/88.7 kB 16%] [Waiting for headers] [Connecting to ppa.l\u001b[0m\u001b[33m\r0% [5 InRelease gpgv 242 kB] [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB\u001b[0m\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\u001b[33m\r0% [5 InRelease gpgv 242 kB] [Waiting for headers] [2 InRelease 43.1 kB/88.7 kB\u001b[0m\u001b[33m\r0% [Waiting for headers] [2 InRelease 43.1 kB/88.7 kB 49%] [Waiting for headers\u001b[0m\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\u001b[33m\r0% [Waiting for headers] [2 InRelease 43.1 kB/88.7 kB 49%] [Waiting for headers\u001b[0m\u001b[33m\r0% [Release.gpg gpgv 697 B] [Waiting for headers] [2 InRelease 43.1 kB/88.7 kB \u001b[0m\r                                                                               \rGet:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\u001b[33m\r0% [Release.gpg gpgv 697 B] [8 InRelease 15.6 kB/88.7 kB 18%] [2 InRelease 43.1\u001b[0m\r                                                                               \rGet:9 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "\u001b[33m\r0% [Release.gpg gpgv 697 B] [8 InRelease 15.6 kB/88.7 kB 18%] [2 InRelease 48.9\u001b[0m\u001b[33m\r0% [8 InRelease 15.6 kB/88.7 kB 18%] [2 InRelease 48.9 kB/88.7 kB 55%] [Waiting\u001b[0m\u001b[33m\r0% [8 InRelease 15.6 kB/88.7 kB 18%] [2 InRelease 54.7 kB/88.7 kB 62%] [Waiting\u001b[0m\u001b[33m\r0% [9 InRelease gpgv 15.4 kB] [8 InRelease 15.6 kB/88.7 kB 18%] [2 InRelease 54\u001b[0m\r                                                                               \rGet:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "\u001b[33m\r0% [9 InRelease gpgv 15.4 kB] [8 InRelease 15.6 kB/88.7 kB 18%] [2 InRelease 57\u001b[0m\u001b[33m\r0% [9 InRelease gpgv 15.4 kB] [8 InRelease 15.6 kB/88.7 kB 18%] [Waiting for he\u001b[0m\u001b[33m\r                                                                               \r0% [8 InRelease 15.6 kB/88.7 kB 18%] [Waiting for headers]\u001b[0m\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [8 InRelease 15.6 kB/88.7 kB 18%] [Waiting for he\u001b[0m\r                                                                               \rGet:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "\u001b[33m\r0% [2 InRelease gpgv 88.7 kB] [8 InRelease 15.6 kB/88.7 kB 18%] [Connecting to \u001b[0m\u001b[33m\r0% [8 InRelease 47.5 kB/88.7 kB 54%] [Connecting to ppa.launchpad.net (91.189.9\u001b[0m\u001b[33m\r0% [12 Release.gpg gpgv 564 B] [8 InRelease 47.5 kB/88.7 kB 54%] [Waiting for h\u001b[0m\u001b[33m\r0% [8 InRelease 47.5 kB/88.7 kB 54%] [Waiting for headers] [Connecting to ppa.l\u001b[0m\r                                                                               \rGet:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [958 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [32.9 kB]\n",
            "Get:15 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,832 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,392 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,253 kB]\n",
            "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [883 kB]\n",
            "Fetched 6,624 kB in 6s (1,021 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "43 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libopenslide0\n",
            "Suggested packages:\n",
            "  libtiff-tools\n",
            "The following NEW packages will be installed:\n",
            "  libopenslide0 openslide-tools\n",
            "0 upgraded, 2 newly installed, 0 to remove and 43 not upgraded.\n",
            "Need to get 92.5 kB of archives.\n",
            "After this operation, 268 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libopenslide0 amd64 3.4.1+dfsg-2 [79.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 openslide-tools amd64 3.4.1+dfsg-2 [12.7 kB]\n",
            "Fetched 92.5 kB in 2s (56.9 kB/s)\n",
            "Selecting previously unselected package libopenslide0.\n",
            "(Reading database ... 144328 files and directories currently installed.)\n",
            "Preparing to unpack .../libopenslide0_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Selecting previously unselected package openslide-tools.\n",
            "Preparing to unpack .../openslide-tools_3.4.1+dfsg-2_amd64.deb ...\n",
            "Unpacking openslide-tools (3.4.1+dfsg-2) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-2) ...\n",
            "Setting up openslide-tools (3.4.1+dfsg-2) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5xIJIvfvHE_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "fe4d698c-ec18-4696-9319-26eaeeb520db"
      },
      "source": [
        "!pip install openslide-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting openslide-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/5a/5b0adeabce81f018a9e4ffe9a419536064bc95c1b12194aff9b7e48f91f7/openslide-python-1.1.1.tar.gz (312kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.9MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 25.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 29.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 26.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 14.4MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 13.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 256kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 276kB 10.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 10.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 10.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 10.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from openslide-python) (7.0.0)\n",
            "Building wheels for collected packages: openslide-python\n",
            "  Building wheel for openslide-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openslide-python: filename=openslide_python-1.1.1-cp36-cp36m-linux_x86_64.whl size=27365 sha256=78b809a005672f5f191c434cb0e876334916fe55e3958f13cebeb2834feb2c88\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/44/7e/16c9fc72cfbf1bffe48676b6835843d21abcc56566e958e7d6\n",
            "Successfully built openslide-python\n",
            "Installing collected packages: openslide-python\n",
            "Successfully installed openslide-python-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD2JsObD-kJS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c82b94a2-23c5-4307-b26d-45382d8926cb"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/CAMELYON17/training/center_0/patient_000.zip\"\n",
        "with ZipFile(file_name,'r') as zip :\n",
        "  zip.extractall()\n",
        "  print('finish')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnGK7dz8BGm5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "d9be2732-81ac-4275-d6ef-8622f7c8f5ed"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import openslide\n",
        "from xml.etree.ElementTree import parse\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "# for multiprocessing\n",
        "import multiprocessing\n",
        "from multiprocessing import Pool, Queue, Process, Array\n",
        "from itertools import repeat\n",
        "\n",
        "# user define variable\n",
        "from user_define import Config as cf\n",
        "from user_define import Hyperparams as hp\n",
        "\n",
        "import pdb\n",
        "\n",
        "\n",
        "class CAMELYON_PREPRO():\n",
        "    \"\"\"\n",
        "    CAMELYON Dataset preprocessed by DEEPBIO\n",
        "    Args:\n",
        "        slide_filename (string) ex) 'b_0'\n",
        "    \"\"\"\n",
        "\n",
        "    # config\n",
        "    level = cf.level_for_preprocessing\n",
        "\n",
        "    # hyper parameters\n",
        "    patch_size = hp.patch_size\n",
        "    num_of_patch = hp.number_of_patch_per_slide\n",
        "    ratio_of_tumor_patch = hp.ratio_of_tumor_patch\n",
        "    threshold_of_tumor_rate = hp.threshold_of_tumor_rate\n",
        "\n",
        "    def __init__(self, usage, slide_filename):\n",
        "        print(\"allocator\", slide_filename)\n",
        "        if usage != 'test':\n",
        "            target_slide_path = os.path.join(cf.path_of_slide,\n",
        "                                             slide_filename + '.tif')\n",
        "            self.slide = openslide.OpenSlide(target_slide_path)\n",
        "            self.downsamples = int(self.slide.level_downsamples[self.level])\n",
        "\n",
        "            xml_filename = slide_filename + \".xml\"\n",
        "            target_xml_path = os.path.join(cf.path_of_annotation,\n",
        "                                           xml_filename)\n",
        "            self.annotation = self.get_annotation_from_xml(target_xml_path)\n",
        "\n",
        "            # for save image\n",
        "            self.patch_path = os.path.join(cf.path_for_result,\n",
        "                                           slide_filename,\n",
        "                                           cf.base_folder_for_patch)\n",
        "            self.check_path(self.patch_path)\n",
        "\n",
        "            self.etc_path = os.path.join(cf.path_for_result,\n",
        "                                         slide_filename,\n",
        "                                         cf.base_folder_for_etc)\n",
        "            self.check_path(self.etc_path)\n",
        "\n",
        "            # for create patch array\n",
        "            self.tissue_mask = self.create_tissue_mask(cf.save_tissue_mask_image)\n",
        "            self.tumor_mask = self.create_tumor_mask(cf.save_tumor_mask_image)\n",
        "\n",
        "            num_of_patch_in_tumor = int(self.num_of_patch * self.ratio_of_tumor_patch)\n",
        "            num_of_patch_in_tissue = self.num_of_patch - num_of_patch_in_tumor\n",
        "\n",
        "            if usage == 'train':\n",
        "                dila_of_tumor, ero_of_tumor = self.get_dilaero(self.tumor_mask)\n",
        "                dila_of_tissue, _ = self.get_dilaero(self.tissue_mask)\n",
        "                set_of_inform_in_tumor = self.get_inform_of_random_samples(\n",
        "                                            ero_of_tumor,\n",
        "                                            num_of_patch_in_tumor)\n",
        "                set_of_inform_in_tissue = self.get_inform_of_random_samples(\n",
        "                                            dila_of_tissue - dila_of_tumor,\n",
        "                                            num_of_patch_in_tissue)\n",
        "\n",
        "            elif usage == 'val':\n",
        "                dila_of_tissue, _ = self.get_dilaero(self.tissue_mask)\n",
        "                set_of_inform_in_tumor = self.get_inform_of_random_samples(\n",
        "                                            self.tumor_mask,\n",
        "                                            num_of_patch_in_tumor)\n",
        "                set_of_inform_in_tissue = self.get_inform_of_random_samples(\n",
        "                                            dila_of_tissue - self.tumor_mask,\n",
        "                                            num_of_patch_in_tissue)\n",
        "\n",
        "            elif usage == 'train_incorrect' or usage == 'val_incorrect':\n",
        "                predict_filename = slide_filename + \"_result.png\"\n",
        "                target_pred_path = os.path.join(cf.path_for_result,\n",
        "                                                slide_filename,\n",
        "                                                cf.base_folder_for_patch,\n",
        "                                                predict_filename,\n",
        "                                                )\n",
        "                predict_array = cv2.imread(target_pred_path, 0)\n",
        "                set_of_inform_in_tumor = self.get_inform_of_random_samples(\n",
        "                                            (predict_array - self.tumor_mask),\n",
        "                                            num_of_patch_in_tumor)\n",
        "                set_of_inform_in_tissue = self.get_inform_of_random_samples(\n",
        "                                            self.tissue_mask,\n",
        "                                            num_of_patch_in_tissue)\n",
        "\n",
        "            else:\n",
        "                raise RuntimeError(\"usage is invalid value\")\n",
        "\n",
        "            self.set_of_inform = set_of_inform_in_tumor + set_of_inform_in_tissue\n",
        "            self.set_of_inform = np.array(self.set_of_inform)\n",
        "\n",
        "            self.set_of_patch = self.get_patch_data(cf.save_patch_images)\n",
        "            self.set_of_patch = np.array(self.set_of_patch)\n",
        "\n",
        "            if cf.save_thumbnail_image:\n",
        "                self.thumbnail = self.create_thumbnail()\n",
        "                self.draw_tumor_pos_on_thumbnail()\n",
        "                self.draw_patch_pos_on_thumbnail()\n",
        "\n",
        "        else :\n",
        "            file_list = os.listdir(cf.path_of_task_1)\n",
        "            file_list.sort()\n",
        "            set_of_patch = []\n",
        "            i = 0\n",
        "            # for fn in tqdm(file_list):\n",
        "            for fn in file_list:\n",
        "                fp = os.path.join(cf.path_of_task_1, fn)\n",
        "                img = cv2.imread(fp, cv2.IMREAD_COLOR)\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                set_of_patch.append(img)\n",
        "                i = i + 1\n",
        "                print(\"\\r%d\" % (i), end=\"\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "            self.set_of_inform = np.array(file_list)\n",
        "            self.set_of_patch = np.array(set_of_patch)\n",
        "\n",
        "        self.create_dataset(usage, slide_filename)\n",
        "\n",
        "    \"\"\"\n",
        "    param :\n",
        "    return : annotations (list of numpy)\n",
        "    \"\"\"\n",
        "\n",
        "    def get_annotation_from_xml(self, target_xml_path):\n",
        "        downsamples = self.downsamples\n",
        "\n",
        "        annotation = []\n",
        "        num_annotation = 0\n",
        "\n",
        "        tree = parse(target_xml_path)\n",
        "        root = tree.getroot()\n",
        "        for Annotation in root.iter(\"Annotation\"):\n",
        "            annotation_list = []\n",
        "            for Coordinate in Annotation.iter(\"Coordinate\"):\n",
        "                x = round(float(Coordinate.attrib[\"X\"]) / downsamples)\n",
        "                y = round(float(Coordinate.attrib[\"Y\"]) / downsamples)\n",
        "                annotation_list.append((x, y))\n",
        "            annotation.append(np.asarray(annotation_list))\n",
        "\n",
        "        return annotation\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    def check_path(self, dir_name):\n",
        "        path = \"\"\n",
        "\n",
        "        while(True):\n",
        "            split = dir_name.split('/', 1)\n",
        "            path = path + split[0] + '/'\n",
        "\n",
        "            if not os.path.isdir(path):\n",
        "                os.mkdir(path)\n",
        "                print(path, \"is created!\")\n",
        "\n",
        "            if len(split) == 1:\n",
        "                break\n",
        "\n",
        "            dir_name = split[1]\n",
        "\n",
        "        return True\n",
        "\n",
        "    \"\"\"\n",
        "    param :\n",
        "    return : tissue_mask (numpy_array)\n",
        "    \"\"\"\n",
        "    def create_tissue_mask(self, save_image=False):\n",
        "        slide = self.slide\n",
        "        level = self.level\n",
        "        col, row = slide.level_dimensions[level]\n",
        "\n",
        "        img = np.array(slide.read_region((0, 0), level, (col, row)))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
        "        img = img[:, :, 1]\n",
        "        _, tissue_mask = cv2.threshold(img,\n",
        "                                       0,\n",
        "                                       255,\n",
        "                                       cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        '''\n",
        "        if save_image:\n",
        "            target_image_path = os.path.join(self.etc_path,\n",
        "                                             \"tissue_mask.jpg\")\n",
        "            cv2.imwrite(target_image_path, tissue_mask)\n",
        "        '''\n",
        "        return tissue_mask\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    param :\n",
        "    return : tumor mask (numpy_array)\n",
        "    \"\"\"\n",
        "    def create_tumor_mask(self, save_image=False):\n",
        "        slide = self.slide\n",
        "        level = self.level\n",
        "        annotation = self.annotation\n",
        "\n",
        "        col, row = slide.level_dimensions[level]\n",
        "        tumor_mask = np.zeros((row, col))\n",
        "        cv2.drawContours(tumor_mask, annotation, -1, 255, -1)\n",
        "\n",
        "        if save_image:\n",
        "            target_image_path = os.path.join(self.etc_path,\n",
        "                                             \"tumor_mask.jpg\")\n",
        "            cv2.imwrite(target_image_path, tumor_mask)\n",
        "\n",
        "\n",
        "        return tumor_mask\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    def get_dilaero(self, mask):\n",
        "        kernel_dilation = np.ones((19, 19), np.uint8)\n",
        "        dilation = cv2.dilate(mask, kernel_dilation, iterations=1)\n",
        "        kernel_erosion = np.ones((9, 9), np.uint8)\n",
        "        erosion = cv2.erode(mask, kernel_erosion, iterations=1)\n",
        "        return dilation, erosion\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    param : mask (numpy)\n",
        "            patch_pos (tuple(x, y, width, height))\n",
        "            percent (what percent will you determine as tumor)\n",
        "            downsamples(int)\n",
        "    return : label (int)\n",
        "    \"\"\"\n",
        "    def determine_tumor(self, patch_pos):\n",
        "        downsamples = self.downsamples\n",
        "        threshold = self.threshold_of_tumor_rate\n",
        "        tumor_mask = self.tumor_mask\n",
        "\n",
        "        min_x = int(patch_pos[0] / downsamples)\n",
        "        min_y = int(patch_pos[1] / downsamples)\n",
        "\n",
        "        width = int(patch_pos[2] / downsamples)\n",
        "        height = int(patch_pos[3] / downsamples)\n",
        "\n",
        "        max_x = int(min_x + width)\n",
        "        max_y = int(min_y + height)\n",
        "\n",
        "        area = width * height\n",
        "\n",
        "        if threshold > 1 or threshold < 0:\n",
        "            raise RuntimeError('threshold must be in 0 to 1')\n",
        "\n",
        "        #\n",
        "        mask_of_patch = tumor_mask[min_y: max_y, min_x: max_x]\n",
        "\n",
        "        #\n",
        "        if np.sum(mask_of_patch) > (threshold * 255 * area):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    param :\n",
        "    return :\n",
        "    \"\"\"\n",
        "    def get_inform_of_random_samples(self, mask, num_of_patch):\n",
        "        slide = self.slide\n",
        "        level = self.level\n",
        "        downsamples = self.downsamples\n",
        "        patch_size = self.patch_size\n",
        "\n",
        "        set_of_inform = []\n",
        "        number_of_region = int(np.sum(mask) / 255)\n",
        "\n",
        "        if number_of_region < num_of_patch:\n",
        "            raise RuntimeError(\n",
        "                'Random size is bigger than number of pixels in region')\n",
        "\n",
        "        mask = np.reshape(mask, -1)\n",
        "        mask_pos = np.argwhere(mask > 0).squeeze()\n",
        "        np.random.shuffle(mask_pos)\n",
        "        dataset_number = mask_pos[:num_of_patch]\n",
        "\n",
        "        width, _ = slide.level_dimensions[level]\n",
        "        goleft = int(patch_size[0] / (2 * downsamples))\n",
        "        goup = int(patch_size[1] / (2 * downsamples))\n",
        "\n",
        "        for data in dataset_number:\n",
        "            x = (data % width - goleft) * downsamples\n",
        "            y = (data // width - goup) * downsamples\n",
        "\n",
        "            is_tumor = self.determine_tumor(\n",
        "                (x, y, patch_size[0], patch_size[1]))\n",
        "            set_of_inform.append(\n",
        "                [is_tumor, x, y, patch_size[0], patch_size[1]])\n",
        "\n",
        "        return set_of_inform\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    param :\n",
        "    return :\n",
        "    \"\"\"\n",
        "    def get_patch_data(self, save_image=False):\n",
        "        slide = self.slide\n",
        "        num_of_patch = self.num_of_patch\n",
        "        set_of_inform = self.set_of_inform\n",
        "        set_of_patch = []\n",
        "\n",
        "        i = 1\n",
        "\n",
        "        if save_image:\n",
        "            print(\"Save patch image\")\n",
        "            for pos in set_of_inform:\n",
        "                is_tumor, x, y, w, h = pos\n",
        "                patch = slide.read_region((x, y), 0, (w, h)).convert(\"RGB\")\n",
        "                set_of_patch.append(np.array(patch))\n",
        "\n",
        "                # for image save\n",
        "                patch_fn = str(x) + \"_\" + str(y) + \"_\" + str(is_tumor) + \".png\"\n",
        "                target_image_path = os.path.join(self.patch_path,\n",
        "                                                 patch_fn)\n",
        "                patch.save(target_image_path)\n",
        "\n",
        "                print(\"\\rPercentage : %d / %d\" % (i, num_of_patch), end=\"\")\n",
        "                i = i + 1\n",
        "\n",
        "            print(\"\\n\")\n",
        "        else:\n",
        "            print(\"Do not save patch image\")\n",
        "            for pos in set_of_inform:\n",
        "                is_tumor, x, y, w, h = pos\n",
        "                patch = slide.read_region((x, y), 0, (w, h)).convert(\"RGB\")\n",
        "                set_of_patch.append(np.array(patch))\n",
        "                print(\"\\rPercentage : %d / %d\" % (i, num_of_patch), end=\"\")\n",
        "                i = i + 1\n",
        "            print(\"\\n\")\n",
        "\n",
        "        return set_of_patch\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    param :\n",
        "    return :\n",
        "    \"\"\"\n",
        "    def create_dataset(self, usage, slide_filename):\n",
        "        set_of_patch = self.set_of_patch\n",
        "        set_of_inform = self.set_of_inform\n",
        "\n",
        "        dataset = {}\n",
        "\n",
        "        dataset[cf.key_of_data] = np.array(set_of_patch)\n",
        "        dataset[cf.key_of_informs] = np.array(set_of_inform)\n",
        "\n",
        "        if usage == 'train':\n",
        "            fp = cf.path_of_train_dataset\n",
        "        elif usage == 'val':\n",
        "            fp = cf.path_of_val_dataset\n",
        "        elif usage == 'test':\n",
        "            fp = cf.path_of_test_dataset\n",
        "        else:\n",
        "            raise RuntimeError(\"usage is invalid value\")\n",
        "\n",
        "        self.check_path(fp)\n",
        "\n",
        "        fn = os.path.join(fp, slide_filename + \".pkl\")\n",
        "        fo = open(fn, 'wb')\n",
        "        pickle.dump(dataset, fo, pickle.HIGHEST_PROTOCOL)\n",
        "        fo.close()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    param : slide file (openslide)\n",
        "            level (int)\n",
        "    return : thumbnail (numpy array)\n",
        "    \"\"\"\n",
        "    def create_thumbnail(self):\n",
        "        col, row = self.slide.level_dimensions[self.level]\n",
        "        thumbnail = self.slide.get_thumbnail((col, row))\n",
        "\n",
        "        thumbnail = np.array(thumbnail)\n",
        "        target_image_path = os.path.join(self.etc_path, \"thumbnail.jpg\")\n",
        "        cv2.imwrite(target_image_path, thumbnail)\n",
        "        return thumbnail\n",
        "\n",
        "    \"\"\"\n",
        "    param :\n",
        "    use : create_thumbnail(slide, level)\n",
        "    return : thumbnail (numpy array)\n",
        "    \"\"\"\n",
        "    def draw_tumor_pos_on_thumbnail(self):\n",
        "        thumbnail = self.thumbnail\n",
        "        annotation = self.annotation\n",
        "\n",
        "        cv2.drawContours(thumbnail, annotation, -1, (0, 255, 0), 4)\n",
        "        target_image_path = os.path.join(self.etc_path,\n",
        "                                         \"tumor_to_thumbnail.jpg\")\n",
        "        cv2.imwrite(target_image_path, thumbnail)\n",
        "\n",
        "        return thumbnail\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    brief :\n",
        "    param :\n",
        "    return :\n",
        "    \"\"\"\n",
        "    def draw_patch_pos_on_thumbnail(self):\n",
        "        set_of_inform = self.set_of_inform\n",
        "        thumbnail = self.thumbnail\n",
        "        downsamples = self.downsamples\n",
        "\n",
        "        for inform in set_of_inform:\n",
        "            is_tumor, x, y, w, h = inform\n",
        "            min_x = int(x/downsamples)\n",
        "            min_y = int(y/downsamples)\n",
        "            max_x = min_x + int(w/downsamples)\n",
        "            max_y = min_y + int(h/downsamples)\n",
        "\n",
        "            if is_tumor:\n",
        "                cv2.rectangle(thumbnail,\n",
        "                              (min_x, min_y),\n",
        "                              (max_x, max_y),\n",
        "                              (255, 0, 0),\n",
        "                              4)\n",
        "            else:\n",
        "                cv2.rectangle(thumbnail,\n",
        "                              (min_x, min_y),\n",
        "                              (max_x, max_y),\n",
        "                              (0, 0, 255),\n",
        "                              4)\n",
        "\n",
        "        target_image_path = os.path.join(self.etc_path,\n",
        "                                         \"patch_pos_to_thumbnail.jpg\")\n",
        "        cv2.imwrite(target_image_path, thumbnail)\n",
        "\n",
        "        return thumbnail\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "def prepro_use_multiprocess(usage, list_of_slide):\n",
        "    print(list_of_slide)\n",
        "    print(usage)\n",
        "    pool = Pool(3)\n",
        "\n",
        "    result = pool.starmap_async(\n",
        "        CAMELYON_PREPRO, zip(repeat(usage), list_of_slide))\n",
        "\n",
        "    result.wait()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "def create_train_dataset(list_of_slide_for_train):\n",
        "    print(\"create train dataset\")\n",
        "    prepro_use_multiprocess(\"train\",\n",
        "                            list_of_slide_for_train)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "def create_val_dataset(list_of_slide_for_val):\n",
        "    print(\"create val dataset\")\n",
        "    prepro_use_multiprocess(\"val\",\n",
        "                            list_of_slide_for_val)\n",
        "\n",
        "\n",
        "def create_incorrect_dataset(list_of_slide_for_incorrect):\n",
        "    print(\"creat incorrect dataset\")\n",
        "    prepro_use_multiprocess(\"train_incorrect\",\n",
        "                            list_of_slide_for_train)\n",
        "\n",
        "    prepro_use_multiprocess(\"val_incorrect\",\n",
        "                            list_of_slide_for_val)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "def create_test_dataset():\n",
        "    print(\"create test dataset\")\n",
        "    CAMELYON_PREPRO(\"test\", \"test\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    start_time = time.time()\n",
        "\n",
        "    create_train_dataset(cf.list_of_slide_for_train)\n",
        "    create_val_dataset(cf.list_of_slide_for_val)\n",
        "    create_incorrect_dataset(cf.list_of_slide_for_incorrect)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"Run time is :  \", end_time - start_time)\n",
        "    print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "create train dataset\n",
            "['b_1', 'b_3', 'b_4', 'b_6', 'b_7', 'b_8', 'b_9', 'b_11', 'b_12', 'b_14']\n",
            "train\n",
            "allocator b_1\n",
            "allocator b_4\n",
            "allocator b_3\n",
            "allocator b_6\n",
            "allocator b_7\n",
            "allocator b_8\n",
            "allocator b_9\n",
            "allocator b_11\n",
            "allocator b_14\n",
            "allocator b_12\n",
            "create val dataset\n",
            "['b_2', 'b_5', 'b_10', 'b_13', 'b_15']\n",
            "val\n",
            "allocator b_5\n",
            "allocator b_10\n",
            "allocator b_13\n",
            "allocator b_2\n",
            "allocator b_15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-e7ada67f860c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mcreate_train_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_of_slide_for_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[0mcreate_val_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_of_slide_for_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     \u001b[0mcreate_incorrect_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_of_slide_for_incorrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'Config' has no attribute 'list_of_slide_for_incorrect'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0UcfotX4AUx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a9e3d92-3970-4869-806d-68712a2789b7"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/My Drive/CAMELYON17/training/lesion_annotations.zip\"\n",
        "with ZipFile(file_name,'r') as zip :\n",
        "  zip.extractall()\n",
        "  print('finish')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0gyMAU-6Wqx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}